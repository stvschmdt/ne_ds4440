{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHDMQyA1Bs-i"
      },
      "source": [
        "# DS4440 - Practical Neural Networks\n",
        "## Week 2 : Image Classification using Multi Layer Perceptron\n",
        "\n",
        "___\n",
        "**Instructor** : Prof. Steve Schmidt <br/>\n",
        "**Teaching Assistants** : Vishwajeet Hogale (hogale.v@northeastern.edu) | Chaitanya Agarwal (agarwal.cha@northeastern.edu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ir5849DYWXs"
      },
      "source": [
        "## Problem Statement\n",
        "\n",
        "Imagine we are working with the Fashion MNIST dataset, a collection of grayscale images representing various fashion items such as shirts, shoes, and bags. By analyzing features such as pixel intensity and patterns in the images, we can uncover insights into how models process and classify visual data.\n",
        "<br/>\n",
        "\n",
        "**Our goal is to take an image as an input and predict the class of the fashion item from the dataset.**\n",
        "<br/>\n",
        "We will demonstrate **both**:\n",
        "- **Binary classification** (classes 0 vs. 1, i.e. T-shirt vs. Trouser)\n",
        "- **Multi-class classification** (all 10 classes)\n",
        "<br/>\n",
        "To accomplish this goal, we will use the **Multi Layer Perceptron**.\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "In this notebook, we'll follow the **six** key sections below:\n",
        "1. **Data Gathering**\n",
        "2. **Data Wrangling**\n",
        "3. **Feature Understanding & Preprocessing**\n",
        "4. **Model Building**\n",
        "5. **Model Validation**\n",
        "6. **Results and Conclusions**\n",
        "\n",
        "Let's dive in and explore how neural networks can tackle this exciting problem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL7mZcKvkWiy"
      },
      "source": [
        "## 0. Setup and Load libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrYBlWWyF7u-"
      },
      "source": [
        "The below cell helps you download all the necessary libraries or packages required to run this notebook without running into any errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
        "sys.path.append(parent_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Aaa1u1vJBs-k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from -r ../../requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from -r ../../requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (from -r ../../requirements.txt (line 3)) (2.4.1)\n",
            "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (from -r ../../requirements.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.11/site-packages (from -r ../../requirements.txt (line 5)) (3.9.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->-r ../../requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->-r ../../requirements.txt (line 1)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->-r ../../requirements.txt (line 1)) (2023.3)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 3)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 3)) (1.13.2)\n",
            "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 3)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 3)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 3)) (2024.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->-r ../../requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->-r ../../requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->-r ../../requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 5)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 5)) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 5)) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r ../../requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch->-r ../../requirements.txt (line 3)) (2.1.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch->-r ../../requirements.txt (line 3)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install -r ../../requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3i02saLeFpi"
      },
      "source": [
        "## 1. Data Gathering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn9U0jGrIAPr"
      },
      "source": [
        "### **About the Dataset**\n",
        "\n",
        "The Fashion MNIST dataset consists of **70,000 labeled grayscale images**, each with a resolution of **28x28 pixels and 10 distinct classes**. This structured dataset allows us to experiment with building and training models, tuning hyperparameters, and evaluating performance.\n",
        "\n",
        "\n",
        "Each training and test example is assigned to one of the following labels:\n",
        "\n",
        "0 T-shirt/top<br/>\n",
        "1 Trouser<br/>\n",
        "2 Pullover<br/>\n",
        "3 Dress<br/>\n",
        "4 Coat<br/>\n",
        "5 Sandal<br/>\n",
        "6 Shirt<br/>\n",
        "7 Sneaker<br/>\n",
        "8 Bag<br/>\n",
        "9 Ankle boot\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "**Dataset Source**\n",
        "<br/>\n",
        "The Fashion MNIST Dataset is a very popular dataset, which is already present in the torch library. What we're going to do is that we will fetch this dataset from torch and download it in our current working directory.\n",
        "<br/><br/>\n",
        "\n",
        "**What is the below cell doing?**<br/>\n",
        "To build a model, it is very important to have a train and test split. Train split helps with training the model. And test split helps with evaluating the performance of the model. That's exactly what we've done below.\n",
        "\n",
        "- train_dataset stores training images in a directory called as data used for training the model\n",
        "- test_dataset stores testing images in a directory called as data used for evaluating the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GFObfWXj3Q2v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/train/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 10604962.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/train/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/train/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/train/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 324201.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/train/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/train/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/train/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5383628.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/train/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/train/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/train/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 6063543.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/train/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/train/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/test/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26421880/26421880 [00:09<00:00, 2843189.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/test/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/test/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 313170.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/test/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 4033527.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/test/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/test/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 3258719.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/test/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/test/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Load the Fashion MNIST training and test datasets from torch\n",
        "train_dataset = datasets.FashionMNIST(\n",
        "    root='./data/train',  # Directory to download the dataset\n",
        "    train=True,  # Load the training set\n",
        "    download=True\n",
        "\n",
        ")\n",
        "\n",
        "test_dataset = datasets.FashionMNIST(\n",
        "    root='./data/test',\n",
        "    train=False,  # Load the test set\n",
        "    download=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3lbt3O8U9U0"
      },
      "source": [
        "### Visualize an image from the training dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-e3KP3AWHVk"
      },
      "source": [
        "Each image belongs to a fashion item that is given a class label.\n",
        "\n",
        "In this instance,<br/>\n",
        "**Ankle boot is represented by the class label 9.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAuHtO2i6-S2",
        "outputId": "d9ff5ca4-aa50-468c-e3f3-ecd4ac14468c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28>, 9)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image, label = train_dataset[0]  # Access the first image and label\n",
        "image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk18PGOzWTsK"
      },
      "source": [
        "To visualize the image, it should be converted to a numpy array so that visualization library can help display the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SLgOcGiRWF26"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "image = np.array(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJjKpB_4WmAR"
      },
      "source": [
        "Display the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "MuS-PofUWh-3",
        "outputId": "e9430fbb-5844-4c65-d489-c7286e775ff2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f\"Label: {label} : Shoe\")\n",
        "plt.axis('off')  # Turn off axes for clarity\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHPF3B1rg8Zh"
      },
      "source": [
        "## 2. Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGKMYTAlhELB"
      },
      "source": [
        "### Check the size of the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ppjGGRzfyJH",
        "outputId": "10884508-20e2-4b9f-b406-5f6a399dcf1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training dataset has 60000 images\n",
            "The testing dataset has 10000 images\n"
          ]
        }
      ],
      "source": [
        "num_images_train = len(train_dataset)\n",
        "num_images_test = len(test_dataset)\n",
        "print(f\"The training dataset has {num_images_train} images\")\n",
        "print(f\"The testing dataset has {num_images_test} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKyrO7d_j0SP"
      },
      "source": [
        "### Explore the class distribution in all the fashion class labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "gOUNf5VLjBcK",
        "outputId": "c425fb16-704f-40fe-de3f-8a830449a50a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get the labels from the dataset\n",
        "labels = np.array(train_dataset.targets)\n",
        "\n",
        "# Count the occurrences of each class label (0 to 9)\n",
        "unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "\n",
        "# Plot the class distribution as a bar chart\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(unique_labels, counts, color='skyblue')\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Class Label Distribution in Fashion MNIST')\n",
        "plt.xticks(unique_labels)  # Set x-ticks to be the class labels\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxeUlPAmcXFx"
      },
      "source": [
        "#### Insights\n",
        "- There are 6000 images in each fashion item class which makes it a well distributed dataset without any class imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wAaaQXwRc6O"
      },
      "source": [
        "## 3. Feature Understanding & Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXcAUpvge8P6"
      },
      "source": [
        "### Model Dataset creation\n",
        "The following cell converts the **images in the data directory** into a **dataframe**, where **each row represents the pixel values of a 28x28 image which will be used by the MLP model**. For the purposes of this notebook, lets assume you were given the dataframe. You may choose to ignore the below two cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8YifGx84cj__"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# function to convert the fashionMNIST dataset to a dataframe\n",
        "# flattens each 28x28 image into 784 columns, plus 1 column for label => 'target'.\n",
        "\n",
        "def build_df(dataset):\n",
        "    num_samples = len(dataset)\n",
        "    images = np.zeros((num_samples, 28 * 28), dtype=np.uint8)  # 28x28 flattened\n",
        "    labels = np.zeros(num_samples, dtype=np.uint8)\n",
        "\n",
        "    # Populate arrays in a single loop\n",
        "    for i, (img_pil, label) in enumerate(dataset):\n",
        "        images[i, :] = np.array(img_pil).flatten()  # Converts a 28 x 28 image into a 784 x 1 row in the dataset\n",
        "        labels[i] = label\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(images)\n",
        "    df['target'] = labels\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "uYjq9VMdf4d8",
        "outputId": "226ea39b-bfc5-4d1e-bb46-92ff79c2a9bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_train shape: (60000, 785)  60,0000 images for training\n",
            "df_test shape:  (10000, 785)  10,000 images for testing\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>114</td>\n",
              "      <td>130</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>96</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3  4  5  6  7   8   9  ...  775  776  777  778  779  780  781  \\\n",
              "0  0  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0    0   \n",
              "1  0  0  0  0  0  1  0  0   0   0  ...  114  130   76    0    0    0    0   \n",
              "2  0  0  0  0  0  0  0  0   0  22  ...    0    1    0    0    0    0    0   \n",
              "3  0  0  0  0  0  0  0  0  33  96  ...    0    0    0    0    0    0    0   \n",
              "4  0  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0    0   \n",
              "\n",
              "   782  783  target  \n",
              "0    0    0       9  \n",
              "1    0    0       0  \n",
              "2    0    0       0  \n",
              "3    0    0       3  \n",
              "4    0    0       0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# build DataFrames for train and test dataset\n",
        "df_train = build_df(train_dataset)\n",
        "df_test = build_df(test_dataset)\n",
        "\n",
        "print(\"df_train shape:\", df_train.shape, \" 60,0000 images for training\")  # expect (60000, 785)\n",
        "print(\"df_test shape: \", df_test.shape, \" 10,000 images for testing\")   # expect (10000, 785)\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Modelling Tasks**\n",
        "#### Binary Classification\n",
        "In this task, we're going to pick any two classes from the fashion MNIST dataset and show how to use Binary Cross Entropy Loss for the binary predictions using MLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3R984kNgep6",
        "outputId": "40c47ef3-7013-4705-db33-81041ba85d5b"
      },
      "outputs": [],
      "source": [
        "# Let's assume we only take fashion class 0 and 1 for binary classification\n",
        "binary_classes = [0, 1]\n",
        "\n",
        "# filter the training dataset on fashion class 0 and 1\n",
        "train_mask = df_train['target'].isin(binary_classes) # This gets all rows that represent fashion items that belong to class 0 or 1\n",
        "\n",
        "# Creates the dataframe that has only two fashion classes i.e 0 or 1. \n",
        "df_train_bin = df_train[train_mask].copy()\n",
        "\n",
        "# repeat for testing dataset\n",
        "test_mask = df_test['target'].isin(binary_classes)\n",
        "df_test_bin = df_test[test_mask].copy()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Multi-Class Classification\n",
        "In this task, we're going to pick all the 10 classes from the fashion MNIST dataset and show how to use Cross Entropy Loss for the multi class predictions using MLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# multi-class DF: we keep all classes 0..9\n",
        "df_train_multi = df_train.copy() # We create copies so that the original df is not disturbed. It's an optional setp.\n",
        "df_test_multi = df_test.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the shapes of the binary and multi-class datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Binary train shape: (12000, 785)\n",
            "Binary test shape:  (2000, 785)\n",
            "Multi-class train shape: (60000, 785)\n",
            "Multi-class test shape:  (10000, 785)\n"
          ]
        }
      ],
      "source": [
        "print(\"Binary train shape:\", df_train_bin.shape)\n",
        "print(\"Binary test shape: \", df_test_bin.shape)\n",
        "print(\"Multi-class train shape:\", df_train_multi.shape)\n",
        "print(\"Multi-class test shape: \", df_test_multi.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The below cell helps you convert the dataframe into **numpy arrays** because torch models **cannot understand Series datatypes (dataframes)**\n",
        "1. It uses all the 784 columns that we created by decomposing an image of size 28x28 as features (X) which the model will learn.\n",
        "2. It uses the target column to predict the fashion class (y) an image belongs to. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RzrW4xPoIHCO"
      },
      "outputs": [],
      "source": [
        "# convert from DataFrame to X,y arrays\n",
        "def df_to_numpy(df):\n",
        "    # separate features from target\n",
        "    X = df.drop(columns=['target']).values  # shape (N,784)\n",
        "    y = df['target'].values  # shape (N,)\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train Test Split \n",
        "This is an important step in model building. In the cells above, we created datasets for two tasks: Binary and Multi-class classification. For each of these tasks, we need to create a training split, which the model uses to learn, and a testing split, which the model uses to evaluate its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XZp8PXKf21B",
        "outputId": "19a878b7-41df-4e69-e216-39772e5ab256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Binary train: (12000, 784) (12000,)\n",
            "Multi train:  (60000, 784) (60000,)\n"
          ]
        }
      ],
      "source": [
        "X_train_bin, y_train_bin = df_to_numpy(df_train_bin)\n",
        "X_test_bin, y_test_bin = df_to_numpy(df_test_bin)\n",
        "\n",
        "# multi\n",
        "X_train_multi, y_train_multi = df_to_numpy(df_train_multi)\n",
        "X_test_multi, y_test_multi = df_to_numpy(df_test_multi)\n",
        "\n",
        "print(\"Binary train:\", X_train_bin.shape, y_train_bin.shape)\n",
        "print(\"Multi train: \", X_train_multi.shape, y_train_multi.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFKwNZwEgFHS",
        "outputId": "9e960791-90f3-4985-c1dc-d9c0034d1ce2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# the data passed to the model will look like this:\n",
        "X_train_bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xAlGmzlfiWpO"
      },
      "outputs": [],
      "source": [
        "# to save the dataframe as a csv file, we can use:\n",
        "#df.to_csv(\"Image_Dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzyS7xHInJKo"
      },
      "source": [
        "## 4. Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Why are we creating batches ?** \n",
        "As we all know, backpropagation occurs when all the rows of a dataset are passed through the model. In the backpropagation step, the model updates the weights after each epoch. This process continues until all epochs are completed.\n",
        "\n",
        "Without batches, the model updates the weights at the end of every epoch, i.e., after the model has read all the rows in the dataset. With batches, the model processes a smaller subset of the data at a time. **This allows the model to update the weights more frequently, typically after each batch, which can lead to faster convergence.** \n",
        "\n",
        "Additionally, **using batches helps in better generalization and can prevent overfitting by providing a more varied set of updates in each epoch. It also helps in reducing memory consumption when working with large datasets that cannot fit entirely into memory.**\n",
        "\n",
        "In essence, batching improves computational efficiency and can lead to more stable and effective learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "msvv2aPnYkg7"
      },
      "outputs": [],
      "source": [
        "# function to manually create batches\n",
        "def create_batches(X, y, batch_size=64, model=None):\n",
        "    num_samples = len(X)\n",
        "    for start in range(0, num_samples, batch_size):\n",
        "        end = start + batch_size\n",
        "        batch_X = X[start:end]\n",
        "        batch_y = y[start:end]\n",
        "        # convert to torch Tensors\n",
        "        batch_X_t = torch.tensor(batch_X, dtype=torch.float32)\n",
        "        # batch_X_t = batch_X.clone().detach().to(torch.float32)\n",
        "\n",
        "        if model==\"MultiClassMLP\":\n",
        "            batch_y_t = torch.tensor(batch_y, dtype=torch.long)\n",
        "        else:\n",
        "          batch_y_t = torch.tensor(batch_y, dtype=torch.float32) # For binary classification, the target (batch_y_t) is typically expected as a torch.float32 tensor\n",
        "        yield batch_X_t, batch_y_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hyperparameters\n",
        "Set your hyperparameters in this cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX5qguSzDB1l",
        "outputId": "d42f137d-785f-4a49-a07b-7b559fcbb843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate: 0.0001\n",
            "Batch size: 64\n",
            "Number of epochs: 10\n",
            "Activation function: ReLU()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "lr = 0.0001 # learning rate\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "num_classes = 10  # number of classes in FashionMNIST\n",
        "\n",
        "\n",
        "activation = nn.ReLU()\n",
        "\n",
        "print('Learning rate:', lr)\n",
        "print('Batch size:', batch_size)\n",
        "print('Number of epochs:', epochs)\n",
        "print('Activation function:', activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "collapsed": true,
        "id": "kPpwX-0JzqTq",
        "outputId": "c7e46031-55ff-4266-d034-6f279239a810"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BinaryMLP(\n",
              "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
              "  (activation): ReLU()\n",
              "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Binary MLP architecture for binary classification\n",
        "        - Input Layer : 784 neurons\n",
        "        - Activation Function : ReLU()\n",
        "        - Hidden Layer : 64 neurons\n",
        "        - Activation Function : Sigmoid()\n",
        "        - Output Layer : 1 neuron  \n",
        "        \n",
        "    - Predicts two classes  \n",
        "\"\"\"\n",
        "\n",
        "class BinaryMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.activation = activation\n",
        "        self.fc2 = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.activation(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out  # shape (batch_size, 1)\n",
        "\n",
        "display(BinaryMLP(784))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "OUpu4sfAYS1X",
        "outputId": "3de1fc49-8625-436e-f4eb-cc3cfb8f0af9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultiClassMLP(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (activation): ReLU()\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"\n",
        "    MLP architecture for binary classification\n",
        "        - Input Layer : 784 neurons\n",
        "        - Activation Function : ReLU()\n",
        "        - Hidden Layer : 64 neurons\n",
        "        - Output Layer : 10 neurons  \n",
        "        \n",
        "    - predicts 10 classes \n",
        "\"\"\"\n",
        "class MultiClassMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=128, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.activation = activation\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.activation(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "display(MultiClassMLP(784))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **What is the training loop doing?**\n",
        "\n",
        "1. **Starting Training Mode**: We tell the model that it's time to learn, so we put it into \"training mode.\"\n",
        "2. **Going Through the Data**: We go through the data many times, just like reading a book over and over until we understand it better. Each time we go through the data, it’s called an **epoch**.\n",
        "3. **Breaking the Data into Small Pieces**: Instead of reading the whole book at once, we break it into smaller pieces (called **batches**), so it’s easier for the model to learn from them one by one.\n",
        "4. **Learning from Each Small Piece**:\n",
        "   - For each small piece (or batch), we give it to the model to make a guess (this is the model's prediction).\n",
        "   - We then check how close or far off the guess was from the actual answer (this is called **loss**).\n",
        "   - The model learns from the mistake and gets a little better by adjusting itself (this is called **backpropagation**).\n",
        "5. **Saving the Model**: After each round of learning, we save what the model has learned so far. If we stop in the middle, we can start again without losing progress.\n",
        "6. **Repeat**: We do this again and again until the model gets better and better at making predictions.\n",
        "\n",
        "After going through all the pieces many times, the model is saved one last time, and we have a trained model that can make good guesses!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mO7gLQ6N4Lif"
      },
      "outputs": [],
      "source": [
        "# training loop\n",
        "def train(model, X_train_np, y_train_np, loss_fn, optimizer, batch_size=64, epochs=5):\n",
        "    model.train()\n",
        "    num_samples = len(X_train_np)\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        for X_batch_t, y_batch_t in create_batches(X_train_np, y_train_np, batch_size, model=model.__class__.__name__):\n",
        "            outputs = model(X_batch_t)\n",
        "            # for binary: shape (N,1), need .squeeze()\n",
        "            loss = loss_fn(outputs.squeeze(), y_batch_t)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(X_batch_t)\n",
        "\n",
        "        avg_loss = total_loss / num_samples\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "        # save the model after every epoch (useful for longer training sessions)\n",
        "        torch.save(model.state_dict(), model.__class__.__name__ + '.pth') # saves it as the model class' name\n",
        "        print(f\"Model saved.\")                                            # example: \"MultiClassMLP.pth\"\n",
        "\n",
        "    # save the model again after the final epoch\n",
        "    torch.save(model.state_dict(), model.__class__.__name__ + '.pth')\n",
        "    print(f\"Final model saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QYZ9mvzTrgBw"
      },
      "outputs": [],
      "source": [
        "# if we want to load a model, we can use:\n",
        "# model = torch.load(\"model.pth\"))\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Making Predictions with the Model**\n",
        "\n",
        "The `predict` function helps the model guess things based on the data we give it. Here’s how it works, step by step:\n",
        "\n",
        "1. **Get the Model Ready to Guess**:\n",
        "   - We tell the model that it’s time to make guesses, not learn new things. This is called **evaluation mode**.\n",
        "\n",
        "2. **Change the Data**:\n",
        "   - If the data we give to the model is in a special format (called a NumPy array), we change it into something the model can understand (called a tensor).\n",
        "\n",
        "3. **Don’t Keep Track of Learning**:\n",
        "   - We tell the model not to remember anything while making predictions. This saves time and makes the prediction faster.\n",
        "\n",
        "4. **Chop the Data into Pieces**:\n",
        "   - If we have a lot of data, we break it into smaller chunks (called **batches**) so the model can handle it better.\n",
        "\n",
        "5. **Let the Model Make Guesses**:\n",
        "   - For each chunk of data, the model looks at it and tries to guess the answer.\n",
        "\n",
        "6. **Pick the Best Guess**:\n",
        "   - After looking at the data, the model picks the best guess (the one with the highest score).\n",
        "\n",
        "7. **Keep All the Guesses**:\n",
        "   - We save all the guesses the model makes for later.\n",
        "\n",
        "8. **Return the Guesses**:\n",
        "   - Once all the guesses are made, we give them back as a list for us to see.\n",
        "\n",
        "This function helps the model make lots of guesses, one batch at a time, without learning anything new.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bdRFOpNO7kff"
      },
      "outputs": [],
      "source": [
        "# model inference\n",
        "def predict(model, X, batch_size):\n",
        "    model.eval()  # set the model to evaluation mode\n",
        "    predictions = []\n",
        "\n",
        "    # if X is a NumPy array, convert it to a PyTorch tensor\n",
        "    if isinstance(X, np.ndarray):\n",
        "        X = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "    with torch.no_grad():  # disable gradient computation for inference\n",
        "        for X_batch, _ in create_batches(X, np.zeros(len(X)), batch_size, model=model):  # Use dummy labels\n",
        "            outputs = model(X_batch)  # forward pass\n",
        "            predicted_classes = torch.argmax(outputs, dim=1)  # get predicted class index\n",
        "            predictions.extend(predicted_classes.numpy())  # convert to NumPy and append\n",
        "\n",
        "    return np.array(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06zj6Xkewt15"
      },
      "source": [
        "### Binary MLP runner\n",
        "This cells calls the train functions defined in the above cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-1GpNkw1arn",
        "outputId": "5e1cd360-8228-41d0-cdb9-b29d4d6f57d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10] - Loss: 0.5604\n",
            "Model saved.\n",
            "Epoch [2/10] - Loss: 0.2186\n",
            "Model saved.\n",
            "Epoch [3/10] - Loss: 0.1759\n",
            "Model saved.\n",
            "Epoch [4/10] - Loss: 0.1396\n",
            "Model saved.\n",
            "Epoch [5/10] - Loss: 0.1170\n",
            "Model saved.\n",
            "Epoch [6/10] - Loss: 0.0991\n",
            "Model saved.\n",
            "Epoch [7/10] - Loss: 0.0903\n",
            "Model saved.\n",
            "Epoch [8/10] - Loss: 0.0692\n",
            "Model saved.\n",
            "Epoch [9/10] - Loss: 0.0563\n",
            "Model saved.\n",
            "Epoch [10/10] - Loss: 0.0511\n",
            "Model saved.\n",
            "Final model saved.\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim # torch package implementing various optimization algorithms\n",
        "\n",
        "input_size = X_train_bin.shape[1]  # number of features in each sample\n",
        "binary_mlp = BinaryMLP(input_size)       # creating an object of the MLP model class\n",
        "optimizer = optim.SGD(binary_mlp.parameters(), lr=lr) # stochastic gradient descent as optimizer\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "\n",
        "train(binary_mlp, X_train_bin, y_train_bin, loss_fn, optimizer, batch_size=batch_size, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPjy1bOlwpSJ"
      },
      "source": [
        "### Multi-class MLP runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XJyjIrBnFlv",
        "outputId": "152afb86-f969-492c-f0ee-a603d0072db8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10] - Loss: 1.9317\n",
            "Model saved.\n",
            "Epoch [2/10] - Loss: 0.7552\n",
            "Model saved.\n",
            "Epoch [3/10] - Loss: 0.6068\n",
            "Model saved.\n",
            "Epoch [4/10] - Loss: 0.5446\n",
            "Model saved.\n",
            "Epoch [5/10] - Loss: 0.5076\n",
            "Model saved.\n",
            "Epoch [6/10] - Loss: 0.4812\n",
            "Model saved.\n",
            "Epoch [7/10] - Loss: 0.4612\n",
            "Model saved.\n",
            "Epoch [8/10] - Loss: 0.4454\n",
            "Model saved.\n",
            "Epoch [9/10] - Loss: 0.4324\n",
            "Model saved.\n",
            "Epoch [10/10] - Loss: 0.4213\n",
            "Model saved.\n",
            "Final model saved.\n"
          ]
        }
      ],
      "source": [
        "input_size = X_train_multi.shape[1]  # number of features in each sample\n",
        "multi_mlp = MultiClassMLP(input_size)       # creating an object of the multi-class MLP model\n",
        "optimizer = optim.SGD(multi_mlp.parameters(), lr=lr) # stochastic gradient descent as optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train(multi_mlp, X_train_multi, y_train_multi, loss_fn, optimizer, batch_size=batch_size, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5PKl6u9xyAV"
      },
      "source": [
        "## 5. Model Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Looking at the Model's Predictions**\n",
        "\n",
        "The `analyze_predictions` function helps us understand how well our model is doing by showing us the **correct** and **incorrect** guesses it made. Here's how it works:\n",
        "\n",
        "1. **Change the Data**:\n",
        "   - The test data (X_test) is of numpy format, and in this cell we can't add acolumns like true_label or predicted_label. So, we convert this numpy array into a Series dataframe.\n",
        "   - If the test data (X_test) is in a special format that the model can't easily read, we change it into a table (called a **DataFrame**).\n",
        "\n",
        "2. **Make Sure the Labels are Ready**:\n",
        "   - We check if the true answers (**y_test**) and the guesses (**y_pred**) are in the right format. If they’re not, we turn them into a simple list.\n",
        "\n",
        "3. **Add the Guesses to the Data**:\n",
        "   - We add the real answers (**true_label**) and the guesses (**predicted_label**) to our table, so we can compare them.\n",
        "\n",
        "4. **Find the Correct and Wrong Guesses**:\n",
        "   - We look at the table and find which guesses were correct and which ones were wrong.\n",
        "\n",
        "5. **Show Some Examples**:\n",
        "   - We pick a few examples (3 at most) of both **correct guesses** and **wrong guesses** and show them to you. This helps us see how the model is doing.\n",
        "\n",
        "6. **Print the Results**:\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1g7Fgebmy2ee"
      },
      "outputs": [],
      "source": [
        "def analyze_predictions(X_test, y_test, y_pred, task=\"binary\"):\n",
        "    # Convert X_test to DataFrame if it's a NumPy array or PyTorch tensor\n",
        "    if isinstance(X_test, (np.ndarray, torch.Tensor)):\n",
        "        X_test = pd.DataFrame(X_test)\n",
        "    \n",
        "    # Ensure y_test and y_pred are in the correct format\n",
        "    if isinstance(y_test, (np.ndarray, torch.Tensor)):\n",
        "        y_test = pd.Series(y_test)\n",
        "    if isinstance(y_pred, (np.ndarray, torch.Tensor)):\n",
        "        y_pred = pd.Series(y_pred)\n",
        "\n",
        "    # Add true and predicted labels to X_test\n",
        "    X_test['true_label'] = y_test\n",
        "    X_test['predicted_label'] = y_pred\n",
        "\n",
        "    # Identify correct and incorrect predictions\n",
        "    correct_preds = X_test[X_test['true_label'] == X_test['predicted_label']]\n",
        "    incorrect_preds = X_test[X_test['true_label'] != X_test['predicted_label']]\n",
        "\n",
        "    # Sample examples for correct and incorrect predictions\n",
        "    correct_examples = correct_preds.sample(n=min(3, len(correct_preds)), random_state=42)\n",
        "    incorrect_examples = incorrect_preds.sample(n=min(3, len(incorrect_preds)), random_state=42)\n",
        "\n",
        "    print(f\"Task: {task}\")\n",
        "    print(\"\\nCorrect Predictions:\")\n",
        "    print(correct_examples)\n",
        "\n",
        "    print(\"\\nIncorrect Predictions:\")\n",
        "    print(incorrect_examples)\n",
        "\n",
        "    return X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WR7hTYDSyPB1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task: binary\n",
            "\n",
            "Correct Predictions:\n",
            "      0  1  2  3  4  5  6  7   8   9  ...  776  777  778  779  780  781  782  \\\n",
            "1009  0  0  0  0  0  0  0  0   0   0  ...  165   23    0    0    0    0    0   \n",
            "1476  0  0  0  0  0  0  0  0   3   0  ...  190   20    0    4    0    0    0   \n",
            "1479  0  0  0  0  0  0  0  0  27  62  ...   20    0    1    0    0    0    0   \n",
            "\n",
            "      783  true_label  predicted_label  \n",
            "1009    0           0                0  \n",
            "1476    0           0                0  \n",
            "1479    0           0                0  \n",
            "\n",
            "[3 rows x 786 columns]\n",
            "\n",
            "Incorrect Predictions:\n",
            "      0  1  2  3  4  5  6  7  8   9  ...  776  777  778  779  780  781  782  \\\n",
            "1078  0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0   \n",
            "1473  0  0  0  0  0  0  0  0  0  86  ...    0    0    0    0    0    0    0   \n",
            "1488  0  0  0  0  0  0  0  0  0  93  ...    0    0    0    0    0    0    0   \n",
            "\n",
            "      783  true_label  predicted_label  \n",
            "1078    0           1                0  \n",
            "1473    0           1                0  \n",
            "1488    0           1                0  \n",
            "\n",
            "[3 rows x 786 columns]\n",
            "Task: multiclass\n",
            "\n",
            "Correct Predictions:\n",
            "      0  1  2  3  4  5  6  7   8    9  ...  776  777  778  779  780  781  782  \\\n",
            "8963  0  0  0  0  0  0  0  0  74  184  ...  205   74    0    2    0    0    0   \n",
            "696   0  0  0  0  0  0  0  2   0    0  ...    0    4  117   80   24    0    0   \n",
            "9553  0  0  0  0  0  0  0  0   0    0  ...    0    0    0    0    0    0    0   \n",
            "\n",
            "      783  true_label  predicted_label  \n",
            "8963    0           0                0  \n",
            "696     0           6                6  \n",
            "9553    0           7                7  \n",
            "\n",
            "[3 rows x 786 columns]\n",
            "\n",
            "Incorrect Predictions:\n",
            "      0  1  2  3  4  5  6  7  8  9  ...  776  777  778  779  780  781  782  \\\n",
            "9961  0  0  0  0  1  0  2  0  0  0  ...    0    0    0    0    0    0    0   \n",
            "2162  0  0  0  0  0  0  0  0  0  0  ...   22   65    4    0    0    0    0   \n",
            "9679  0  0  0  0  0  0  0  2  2  0  ...   85   52    0    0    0    0    0   \n",
            "\n",
            "      783  true_label  predicted_label  \n",
            "9961    0           6                2  \n",
            "2162    0           6                4  \n",
            "9679    0           4                6  \n",
            "\n",
            "[3 rows x 786 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/31/vhwm53rj4tnfvv9lgq9m3x5w0000gn/T/ipykernel_24193/4025120938.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  batch_X_t = torch.tensor(batch_X, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "# running inference on test set\n",
        "y_pred_bin = predict(binary_mlp, X_test_bin, batch_size)\n",
        "y_pred_multi = predict(multi_mlp, X_test_multi, batch_size)\n",
        "\n",
        "# analyze binary predictions\n",
        "binary_results = analyze_predictions(X_test_bin, y_test_bin, y_pred_bin, task=\"binary\")\n",
        "\n",
        "# Analyze multi-class predictions\n",
        "multi_results = analyze_predictions(X_test_multi, y_test_multi, y_pred_multi, task=\"multiclass\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeVC9VuU0fXD"
      },
      "source": [
        "## 6. Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using confusion matrix to evaluate the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QVrpkQaKzxd_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import torch\n",
        "\n",
        "def evaluate(model, X_test, y_test, task=\"binary\", threshold=0.5):\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        # convert test features to PyTorch tensors\n",
        "        X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "        # get model outputs\n",
        "        outputs = model(X_test_t)\n",
        "\n",
        "        if task == \"binary\":\n",
        "            # for binary classification, apply threshold\n",
        "            preds = (outputs.squeeze().numpy() >= threshold).astype(int)\n",
        "        elif task == \"multiclass\":\n",
        "            # for multi-class classification, get the class with the highest score\n",
        "            preds = torch.argmax(outputs, dim=1).numpy()\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported task type: {task}. Use 'binary' or 'multiclass'.\")\n",
        "\n",
        "    # calculate accuracy and confusion matrix\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "\n",
        "    return accuracy, cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Confusion Matrix**\n",
        "##### **What is a Confusion Matrix?**\n",
        "\n",
        "A **confusion matrix** is like a special table that helps us see how well our model is guessing things. Imagine you’re trying to guess if an animal is a **cat** or a **dog**.\n",
        "\n",
        "Here’s how it works:\n",
        "\n",
        "1. **Four Boxes**:\n",
        "   - The confusion matrix has four boxes (like four corners):\n",
        "     - **Top-left box**: This is for when the model **guessed cat and it was a cat**. \n",
        "     - **Top-right box**: This is for when the model **guessed cat but it was a dog**. \n",
        "     - **Bottom-left box**: This is for when the model **guessed dog but it was a cat**. \n",
        "     - **Bottom-right box**: This is for when the model **guessed dog and it was a dog**. \n",
        "\n",
        "2. **What Do These Boxes Mean?**:\n",
        "   - **True Positives (Top-left & Bottom-right)**: The model made the right guess! It got **cat when it was a cat** or **dog when it was a dog**.\n",
        "   - **False Positives (Top-right)**: The model **guessed cat when it was a dog**. Oops!\n",
        "   - **False Negatives (Bottom-left)**: The model **guessed dog when it was a cat**. Oops again!\n",
        "   - **True Negatives (Bottom-right)**: The model made the right guess again, **dog when it was a dog**.\n",
        "\n",
        "3. **Why Is It Helpful?**:\n",
        "   - The confusion matrix helps us understand **where the model is getting things wrong** and where it is doing well. It tells us how often the model is confused between **cat** and **dog**.\n",
        "\n",
        "The confusion matrix helps us make our model smarter by showing where it needs to learn better. 📊\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV7W0BW3snmg",
        "outputId": "83bc4311-e8dd-4450-e877-b121164e8e33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Binary Test Accuracy: 0.984\n",
            "Binary Confusion Matrix:\n",
            "[[990  10]\n",
            " [ 22 978]]\n"
          ]
        }
      ],
      "source": [
        "# confusion Matrix for binary classification:\n",
        "# [[TN, FP],\n",
        "# [FN, TP]]\n",
        "accuracy_bin, cm_bin = evaluate(binary_mlp, X_test_bin, y_test_bin, task=\"binary\")\n",
        "print(\"\\nBinary Test Accuracy:\", accuracy_bin)\n",
        "print(\"Binary Confusion Matrix:\")\n",
        "print(cm_bin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ai2-uI4vtQRc",
        "outputId": "f6140150-1174-44c1-fa54-3436976a87aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Multi-Class Test Accuracy: 0.834\n",
            "Multi-Class Confusion Matrix:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[837,  11,  20,  33,  13,   2,  68,   0,  16,   0],\n",
              "       [  9, 955,   5,  21,   6,   0,   2,   0,   2,   0],\n",
              "       [ 13,   5, 699,  10, 169,   1,  95,   0,   8,   0],\n",
              "       [ 44,  15,  18, 827,  47,   2,  37,   0,  10,   0],\n",
              "       [  4,   0,  83,  33, 795,   0,  79,   0,   5,   1],\n",
              "       [  0,   0,   0,   0,   0, 907,   1,  46,  10,  36],\n",
              "       [201,   2,  84,  31, 127,   0, 524,   0,  31,   0],\n",
              "       [  0,   0,   0,   0,   0,  37,   0, 931,   4,  28],\n",
              "       [ 16,   0,   7,   4,   6,   4,  19,   7, 936,   1],\n",
              "       [  0,   0,   0,   1,   0,  15,   1,  50,   4, 929]])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# multi-Class classification\n",
        "accuracy_multi, cm_multi = evaluate(multi_mlp, X_test_multi, y_test_multi, task=\"multiclass\")\n",
        "print(\"\\nMulti-Class Test Accuracy:\", accuracy_multi)\n",
        "print(\"Multi-Class Confusion Matrix:\")\n",
        "display(cm_multi)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ggZaP1pRjBnO"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
