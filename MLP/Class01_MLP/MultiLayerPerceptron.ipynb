{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHDMQyA1Bs-i"
      },
      "source": [
        "# DS4440 - Practical Neural Networks\n",
        "## Week 2 : Image Classification using Multi Layer Perceptron\n",
        "\n",
        "___\n",
        "**Instructor** : Prof. Steve Schmidt <br/>\n",
        "**Teaching Assistants** : Vishwajeet Hogale (hogale.v@northeastern.edu) | Chaitanya Agarwal (agarwal.cha@northeastern.edu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ir5849DYWXs"
      },
      "source": [
        "## Problem Statement\n",
        "\n",
        "Imagine we are working with the Fashion MNIST dataset, a collection of grayscale images representing various fashion items such as shirts, shoes, and bags. By analyzing features such as pixel intensity and patterns in the images, we can uncover insights into how models process and classify visual data.\n",
        "<br/>\n",
        "\n",
        "**Our goal is to take an image as an input and predict the class of the fashion item from the dataset.**\n",
        "<br/>\n",
        "We will demonstrate **both**:\n",
        "- **Binary classification** (classes 0 vs. 1, i.e. T-shirt vs. Trouser)\n",
        "- **Multi-class classification** (all 10 classes)\n",
        "<br/>\n",
        "To accomplish this goal, we will use the **Multi Layer Perceptron**.\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "In this notebook, we'll follow the **six** key sections below:\n",
        "1. **Data Gathering**\n",
        "2. **Data Wrangling**\n",
        "3. **Feature Understanding & Preprocessing**\n",
        "4. **Model Building**\n",
        "5. **Model Validation**\n",
        "6. **Results and Conclusions**\n",
        "\n",
        "Let's dive in and explore how neural networks can tackle this exciting problem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL7mZcKvkWiy"
      },
      "source": [
        "## 0. Setup and Load libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below cell helps you download all the necessary libraries or packages required to run this notebook without running into any errors."
      ],
      "metadata": {
        "id": "MrYBlWWyF7u-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aaa1u1vJBs-k"
      },
      "outputs": [],
      "source": [
        "! pip install -r ../../requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3i02saLeFpi"
      },
      "source": [
        "## 1. Data Gathering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **About the Dataset**\n",
        "\n",
        "The Fashion MNIST dataset consists of **70,000 labeled grayscale images**, each with a resolution of **28x28 pixels and 10 distinct classes**. This structured dataset allows us to experiment with building and training models, tuning hyperparameters, and evaluating performance.\n",
        "\n",
        "\n",
        "Each training and test example is assigned to one of the following labels:\n",
        "\n",
        "0 T-shirt/top<br/>\n",
        "1 Trouser<br/>\n",
        "2 Pullover<br/>\n",
        "3 Dress<br/>\n",
        "4 Coat<br/>\n",
        "5 Sandal<br/>\n",
        "6 Shirt<br/>\n",
        "7 Sneaker<br/>\n",
        "8 Bag<br/>\n",
        "9 Ankle boot\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "**Dataset Source**\n",
        "<br/>\n",
        "The Fashion MNIST Dataset is a very popular dataset, which is already present in the torch library. What we're going to do is that we will fetch this dataset from torch and download it in our current working directory.\n",
        "<br/><br/>\n",
        "\n",
        "**What is the below cell doing?**<br/>\n",
        "To build a model, it is very important to have a train and test split. Train split helps with training the model. And test split helps with evaluating the performance of the model. That's exactly what we've done below.\n",
        "\n",
        "- train_dataset stores training images in a directory called as data used for training the model\n",
        "- test_dataset stores testing images in a directory called as data used for evaluating the model\n",
        "\n"
      ],
      "metadata": {
        "id": "Pn9U0jGrIAPr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "GFObfWXj3Q2v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Load the Fashion MNIST training and test datasets from torch\n",
        "train_dataset = datasets.FashionMNIST(\n",
        "    root='./data/train',  # Directory to download the dataset\n",
        "    train=True,  # Load the training set\n",
        "    download=True\n",
        "\n",
        ")\n",
        "\n",
        "test_dataset = datasets.FashionMNIST(\n",
        "    root='./data/test',\n",
        "    train=False,  # Load the test set\n",
        "    download=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize an image from the training dataset"
      ],
      "metadata": {
        "id": "n3lbt3O8U9U0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each image belongs to a fashion item that is given a class label.\n",
        "\n",
        "In this instance,<br/>\n",
        "**Ankle boot is represented by the class label 9.**\n",
        "\n"
      ],
      "metadata": {
        "id": "a-e3KP3AWHVk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAuHtO2i6-S2",
        "outputId": "d9ff5ca4-aa50-468c-e3f3-ecd4ac14468c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28>, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "image, label = train_dataset[0]  # Access the first image and label\n",
        "image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the image, it should be converted to a numpy array so that visualization library can help display the image."
      ],
      "metadata": {
        "id": "gk18PGOzWTsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "image = np.array(image)"
      ],
      "metadata": {
        "id": "SLgOcGiRWF26"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the image"
      ],
      "metadata": {
        "id": "kJjKpB_4WmAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f\"Label: {label} : Shoe\")\n",
        "plt.axis('off')  # Turn off axes for clarity\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "MuS-PofUWh-3",
        "outputId": "e9430fbb-5844-4c65-d489-c7286e775ff2"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHPF3B1rg8Zh"
      },
      "source": [
        "## 2. Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGKMYTAlhELB"
      },
      "source": [
        "### Check the size of the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ppjGGRzfyJH",
        "outputId": "10884508-20e2-4b9f-b406-5f6a399dcf1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training dataset has 60000 images\n",
            "The testing dataset has 10000 images\n"
          ]
        }
      ],
      "source": [
        "num_images_train = len(train_dataset)\n",
        "num_images_test = len(test_dataset)\n",
        "print(f\"The training dataset has {num_images_train} images\")\n",
        "print(f\"The testing dataset has {num_images_test} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKyrO7d_j0SP"
      },
      "source": [
        "### Explore the class distribution in all the fashion class labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "gOUNf5VLjBcK",
        "outputId": "c425fb16-704f-40fe-de3f-8a830449a50a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get the labels from the dataset\n",
        "labels = np.array(train_dataset.targets)\n",
        "\n",
        "# Count the occurrences of each class label (0 to 9)\n",
        "unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "\n",
        "# Plot the class distribution as a bar chart\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(unique_labels, counts, color='skyblue')\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Class Label Distribution in Fashion MNIST')\n",
        "plt.xticks(unique_labels)  # Set x-ticks to be the class labels\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Insights\n",
        "- There are 6000 images in each fashion item class which makes it a well distributed dataset without any class imbalance."
      ],
      "metadata": {
        "id": "jxeUlPAmcXFx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wAaaQXwRc6O"
      },
      "source": [
        "## 3. Feature Understanding & Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Dataset creation\n",
        "The following cell converts the images in the data directory into a dataframe, where each row represents the pixel values of a 28x28 image which will be used by the MLP model. For the purposes of this notebook, lets assume you were given the dataframe. You may choose to ignore the below two cells.\n"
      ],
      "metadata": {
        "id": "tXcAUpvge8P6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# function to convert the fashionMNIST dataset to a dataframe\n",
        "# flattens each 28x28 image into 784 columns, plus 1 column for label => 'target'.\n",
        "\n",
        "def build_df(dataset):\n",
        "    num_samples = len(dataset)\n",
        "    images = np.zeros((num_samples, 28 * 28), dtype=np.uint8)  # 28x28 flattened\n",
        "    labels = np.zeros(num_samples, dtype=np.uint8)\n",
        "\n",
        "    # Populate arrays in a single loop\n",
        "    for i, (img_pil, label) in enumerate(dataset):\n",
        "        images[i, :] = np.array(img_pil).flatten()  # Convert and flatten image\n",
        "        labels[i] = label\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(images)\n",
        "    df['target'] = labels\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "8YifGx84cj__"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build DataFrames for train and test\n",
        "df_train = build_df(train_dataset)\n",
        "df_test = build_df(test_dataset)\n",
        "\n",
        "print(\"df_train shape:\", df_train.shape)  # expect (60000, 785)\n",
        "print(\"df_test shape: \", df_test.shape)   # expect (10000, 785)\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "uYjq9VMdf4d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "226ea39b-bfc5-4d1e-bb46-92ff79c2a9bf"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_train shape: (60000, 785)\n",
            "df_test shape:  (10000, 785)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4  5  6  7   8   9  ...  775  776  777  778  779  780  781  \\\n",
              "0  0  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0    0   \n",
              "1  0  0  0  0  0  1  0  0   0   0  ...  114  130   76    0    0    0    0   \n",
              "2  0  0  0  0  0  0  0  0   0  22  ...    0    1    0    0    0    0    0   \n",
              "3  0  0  0  0  0  0  0  0  33  96  ...    0    0    0    0    0    0    0   \n",
              "4  0  0  0  0  0  0  0  0   0   0  ...    0    0    0    0    0    0    0   \n",
              "\n",
              "   782  783  target  \n",
              "0    0    0       9  \n",
              "1    0    0       0  \n",
              "2    0    0       0  \n",
              "3    0    0       3  \n",
              "4    0    0       0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-261fec3d-8c76-49b5-bdfa-a4da8d6c4b0e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>114</td>\n",
              "      <td>130</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>96</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-261fec3d-8c76-49b5-bdfa-a4da8d6c4b0e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-261fec3d-8c76-49b5-bdfa-a4da8d6c4b0e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-261fec3d-8c76-49b5-bdfa-a4da8d6c4b0e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-954e2c6f-0f64-4fad-bf0f-4f61f4414ae9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-954e2c6f-0f64-4fad-bf0f-4f61f4414ae9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-954e2c6f-0f64-4fad-bf0f-4f61f4414ae9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build separate DataFrames for binary and multi for train & test\n",
        "# binary DF: only rows where target is 0 or 1\n",
        "binary_classes = [0, 1]\n",
        "\n",
        "# filter the training dataset\n",
        "# create a boolean mask where the target column is either 0 or 1\n",
        "train_mask = df_train['target'].isin(binary_classes)\n",
        "\n",
        "# use the mask to filter the rows from the training dataset\n",
        "df_train_bin = df_train[train_mask].copy()\n",
        "\n",
        "# repeat for testing dataset\n",
        "test_mask = df_test['target'].isin(binary_classes)\n",
        "df_test_bin = df_test[test_mask].copy()\n",
        "\n",
        "# multi-class DF: we keep all classes 0..9\n",
        "df_train_multi = df_train.copy()\n",
        "df_test_multi = df_test.copy()\n",
        "\n",
        "print(\"Binary train shape:\", df_train_bin.shape)\n",
        "print(\"Binary test shape: \", df_test_bin.shape)\n",
        "print(\"Multi-class train shape:\", df_train_multi.shape)\n",
        "print(\"Multi-class test shape: \", df_test_multi.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3R984kNgep6",
        "outputId": "40c47ef3-7013-4705-db33-81041ba85d5b"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary train shape: (12000, 785)\n",
            "Binary test shape:  (2000, 785)\n",
            "Multi-class train shape: (60000, 785)\n",
            "Multi-class test shape:  (10000, 785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert from DataFrame to X,y arrays\n",
        "def df_to_numpy(df):\n",
        "    # separate features from target\n",
        "    X = df.drop(columns=['target']).values  # shape (N,784)\n",
        "    y = df['target'].values  # shape (N,)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "RzrW4xPoIHCO"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_bin, y_train_bin = df_to_numpy(df_train_bin)\n",
        "X_test_bin, y_test_bin = df_to_numpy(df_test_bin)\n",
        "\n",
        "# multi\n",
        "X_train_multi, y_train_multi = df_to_numpy(df_train_multi)\n",
        "X_test_multi, y_test_multi = df_to_numpy(df_test_multi)\n",
        "\n",
        "print(\"Binary train:\", X_train_bin.shape, y_train_bin.shape)\n",
        "print(\"Multi train: \", X_train_multi.shape, y_train_multi.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XZp8PXKf21B",
        "outputId": "19a878b7-41df-4e69-e216-39772e5ab256"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary train: (12000, 784) (12000,)\n",
            "Multi train:  (60000, 784) (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the data passed to the model will look like this:\n",
        "X_train_bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFKwNZwEgFHS",
        "outputId": "9e960791-90f3-4985-c1dc-d9c0034d1ce2"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to save the dataframe as a csv file, we can use:\n",
        "#df.to_csv(\"Image_Dataset.csv\")"
      ],
      "metadata": {
        "id": "xAlGmzlfiWpO"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzyS7xHInJKo"
      },
      "source": [
        "## 4. Model Building"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to manually create batches\n",
        "def create_batches(X, y, batch_size=64, model=None):\n",
        "    num_samples = len(X)\n",
        "    for start in range(0, num_samples, batch_size):\n",
        "        end = start + batch_size\n",
        "        batch_X = X[start:end]\n",
        "        batch_y = y[start:end]\n",
        "        # convert to torch Tensors\n",
        "        batch_X_t = torch.tensor(batch_X, dtype=torch.float32)\n",
        "        if model==\"MultiClassMLP\":\n",
        "            batch_y_t = torch.tensor(batch_y, dtype=torch.long)\n",
        "        else:\n",
        "          batch_y_t = torch.tensor(batch_y, dtype=torch.float32) # For binary classification, the target (batch_y_t) is typically expected as a torch.float32 tensor\n",
        "        yield batch_X_t, batch_y_t"
      ],
      "metadata": {
        "id": "msvv2aPnYkg7"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "import torch.nn as nn\n",
        "\n",
        "lr = 0.0001 # learning rate\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "num_classes = 10  # number of classes in FashionMNIST\n",
        "\n",
        "\n",
        "activation = nn.ReLU()\n",
        "\n",
        "print('Learning rate:', lr)\n",
        "print('Batch size:', batch_size)\n",
        "print('Number of epochs:', epochs)\n",
        "print('Activation function:', activation)"
      ],
      "metadata": {
        "id": "gX5qguSzDB1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42f137d-785f-4a49-a07b-7b559fcbb843"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.0001\n",
            "Batch size: 64\n",
            "Number of epochs: 50\n",
            "Activation function: ReLU()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "kPpwX-0JzqTq",
        "outputId": "c7e46031-55ff-4266-d034-6f279239a810",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "BinaryMLP(\n",
              "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
              "  (activation): ReLU()\n",
              "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# MLP architecture for binary classification\n",
        "class BinaryMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.activation = activation\n",
        "        self.fc2 = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.activation(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out  # shape (batch_size, 1)\n",
        "\n",
        "display(BinaryMLP(784))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP architecture for multi-class classification\n",
        "class MultiClassMLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=128, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.activation = activation\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.activation(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "display(MultiClassMLP(784))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "OUpu4sfAYS1X",
        "outputId": "3de1fc49-8625-436e-f4eb-cc3cfb8f0af9"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "MultiClassMLP(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (activation): ReLU()\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "def train(model, X_train_np, y_train_np, loss_fn, optimizer, batch_size=64, epochs=5):\n",
        "    model.train()\n",
        "    num_samples = len(X_train_np)\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        for X_batch_t, y_batch_t in create_batches(X_train_np, y_train_np, batch_size, model=model.__class__.__name__):\n",
        "            outputs = model(X_batch_t)\n",
        "            # for binary: shape (N,1), need .squeeze()\n",
        "            loss = loss_fn(outputs.squeeze(), y_batch_t)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(X_batch_t)\n",
        "\n",
        "        avg_loss = total_loss / num_samples\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "        # save the model after every epoch (useful for longer training sessions)\n",
        "        torch.save(model.state_dict(), model.__class__.__name__ + '.pth') # saves it as the model class' name\n",
        "        print(f\"Model saved.\")                                            # example: \"MultiClassMLP.pth\"\n",
        "\n",
        "    # save the model again after the final epoch\n",
        "    torch.save(model.state_dict(), model.__class__.__name__ + '.pth')\n",
        "    print(f\"Final model saved.\")"
      ],
      "metadata": {
        "id": "mO7gLQ6N4Lif"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we want to load a model, we can use:\n",
        "# model = torch.load(\"model.pth\"))\n",
        "# model.eval()"
      ],
      "metadata": {
        "id": "QYZ9mvzTrgBw"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model inference\n",
        "def predict(model, X, batch_size):\n",
        "    model.eval()  # set the model to evaluation mode\n",
        "    predictions = []\n",
        "\n",
        "    # if X is a NumPy array, convert it to a PyTorch tensor\n",
        "    if isinstance(X, np.ndarray):\n",
        "        X = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "    with torch.no_grad():  # disable gradient computation for inference\n",
        "        for X_batch, _ in create_batches(X, np.zeros(len(X)), batch_size, model=model):  # Use dummy labels\n",
        "            outputs = model(X_batch)  # forward pass\n",
        "            predicted_classes = torch.argmax(outputs, dim=1)  # get predicted class index\n",
        "            predictions.extend(predicted_classes.numpy())  # convert to NumPy and append\n",
        "\n",
        "    return np.array(predictions)"
      ],
      "metadata": {
        "id": "bdRFOpNO7kff"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binary MLP runner"
      ],
      "metadata": {
        "id": "06zj6Xkewt15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim # torch package implementing various optimization algorithms\n",
        "\n",
        "input_size = X_train_bin.shape[1]  # number of features in each sample\n",
        "binary_mlp = BinaryMLP(input_size)       # creating an object of the MLP model class\n",
        "optimizer = optim.SGD(binary_mlp.parameters(), lr=lr) # stochastic gradient descent as optimizer\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "\n",
        "train(binary_mlp, X_train_bin, y_train_bin, loss_fn, optimizer, batch_size=batch_size, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-1GpNkw1arn",
        "outputId": "5e1cd360-8228-41d0-cdb9-b29d4d6f57d0"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] - Loss: 4.3814\n",
            "Model saved.\n",
            "Epoch [2/50] - Loss: 0.1987\n",
            "Model saved.\n",
            "Epoch [3/50] - Loss: 0.1437\n",
            "Model saved.\n",
            "Epoch [4/50] - Loss: 0.1227\n",
            "Model saved.\n",
            "Epoch [5/50] - Loss: 0.1092\n",
            "Model saved.\n",
            "Epoch [6/50] - Loss: 0.0996\n",
            "Model saved.\n",
            "Epoch [7/50] - Loss: 0.0920\n",
            "Model saved.\n",
            "Epoch [8/50] - Loss: 0.0857\n",
            "Model saved.\n",
            "Epoch [9/50] - Loss: 0.0803\n",
            "Model saved.\n",
            "Epoch [10/50] - Loss: 0.0755\n",
            "Model saved.\n",
            "Epoch [11/50] - Loss: 0.0714\n",
            "Model saved.\n",
            "Epoch [12/50] - Loss: 0.0677\n",
            "Model saved.\n",
            "Epoch [13/50] - Loss: 0.0644\n",
            "Model saved.\n",
            "Epoch [14/50] - Loss: 0.0615\n",
            "Model saved.\n",
            "Epoch [15/50] - Loss: 0.0588\n",
            "Model saved.\n",
            "Epoch [16/50] - Loss: 0.0564\n",
            "Model saved.\n",
            "Epoch [17/50] - Loss: 0.0543\n",
            "Model saved.\n",
            "Epoch [18/50] - Loss: 0.0522\n",
            "Model saved.\n",
            "Epoch [19/50] - Loss: 0.0504\n",
            "Model saved.\n",
            "Epoch [20/50] - Loss: 0.0488\n",
            "Model saved.\n",
            "Epoch [21/50] - Loss: 0.0473\n",
            "Model saved.\n",
            "Epoch [22/50] - Loss: 0.0388\n",
            "Model saved.\n",
            "Epoch [23/50] - Loss: 0.0306\n",
            "Model saved.\n",
            "Epoch [24/50] - Loss: 0.0292\n",
            "Model saved.\n",
            "Epoch [25/50] - Loss: 0.0279\n",
            "Model saved.\n",
            "Epoch [26/50] - Loss: 0.0268\n",
            "Model saved.\n",
            "Epoch [27/50] - Loss: 0.0257\n",
            "Model saved.\n",
            "Epoch [28/50] - Loss: 0.0247\n",
            "Model saved.\n",
            "Epoch [29/50] - Loss: 0.0238\n",
            "Model saved.\n",
            "Epoch [30/50] - Loss: 0.0229\n",
            "Model saved.\n",
            "Epoch [31/50] - Loss: 0.0221\n",
            "Model saved.\n",
            "Epoch [32/50] - Loss: 0.0213\n",
            "Model saved.\n",
            "Epoch [33/50] - Loss: 0.0205\n",
            "Model saved.\n",
            "Epoch [34/50] - Loss: 0.0198\n",
            "Model saved.\n",
            "Epoch [35/50] - Loss: 0.0191\n",
            "Model saved.\n",
            "Epoch [36/50] - Loss: 0.0184\n",
            "Model saved.\n",
            "Epoch [37/50] - Loss: 0.0178\n",
            "Model saved.\n",
            "Epoch [38/50] - Loss: 0.0173\n",
            "Model saved.\n",
            "Epoch [39/50] - Loss: 0.0167\n",
            "Model saved.\n",
            "Epoch [40/50] - Loss: 0.0162\n",
            "Model saved.\n",
            "Epoch [41/50] - Loss: 0.0157\n",
            "Model saved.\n",
            "Epoch [42/50] - Loss: 0.0153\n",
            "Model saved.\n",
            "Epoch [43/50] - Loss: 0.0148\n",
            "Model saved.\n",
            "Epoch [44/50] - Loss: 0.0145\n",
            "Model saved.\n",
            "Epoch [45/50] - Loss: 0.0141\n",
            "Model saved.\n",
            "Epoch [46/50] - Loss: 0.0137\n",
            "Model saved.\n",
            "Epoch [47/50] - Loss: 0.0134\n",
            "Model saved.\n",
            "Epoch [48/50] - Loss: 0.0130\n",
            "Model saved.\n",
            "Epoch [49/50] - Loss: 0.0127\n",
            "Model saved.\n",
            "Epoch [50/50] - Loss: 0.0124\n",
            "Model saved.\n",
            "Final model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-class MLP runner"
      ],
      "metadata": {
        "id": "DPjy1bOlwpSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train_multi.shape[1]  # number of features in each sample\n",
        "multi_mlp = MultiClassMLP(input_size)       # creating an object of the multi-class MLP model\n",
        "optimizer = optim.SGD(multi_mlp.parameters(), lr=lr) # stochastic gradient descent as optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train(multi_mlp, X_train_multi, y_train_multi, loss_fn, optimizer, batch_size=batch_size, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XJyjIrBnFlv",
        "outputId": "152afb86-f969-492c-f0ee-a603d0072db8"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] - Loss: 1.7239\n",
            "Model saved.\n",
            "Epoch [2/50] - Loss: 0.7178\n",
            "Model saved.\n",
            "Epoch [3/50] - Loss: 0.5948\n",
            "Model saved.\n",
            "Epoch [4/50] - Loss: 0.5389\n",
            "Model saved.\n",
            "Epoch [5/50] - Loss: 0.5050\n",
            "Model saved.\n",
            "Epoch [6/50] - Loss: 0.4812\n",
            "Model saved.\n",
            "Epoch [7/50] - Loss: 0.4629\n",
            "Model saved.\n",
            "Epoch [8/50] - Loss: 0.4483\n",
            "Model saved.\n",
            "Epoch [9/50] - Loss: 0.4361\n",
            "Model saved.\n",
            "Epoch [10/50] - Loss: 0.4257\n",
            "Model saved.\n",
            "Epoch [11/50] - Loss: 0.4167\n",
            "Model saved.\n",
            "Epoch [12/50] - Loss: 0.4087\n",
            "Model saved.\n",
            "Epoch [13/50] - Loss: 0.4015\n",
            "Model saved.\n",
            "Epoch [14/50] - Loss: 0.3949\n",
            "Model saved.\n",
            "Epoch [15/50] - Loss: 0.3890\n",
            "Model saved.\n",
            "Epoch [16/50] - Loss: 0.3835\n",
            "Model saved.\n",
            "Epoch [17/50] - Loss: 0.3784\n",
            "Model saved.\n",
            "Epoch [18/50] - Loss: 0.3738\n",
            "Model saved.\n",
            "Epoch [19/50] - Loss: 0.3695\n",
            "Model saved.\n",
            "Epoch [20/50] - Loss: 0.3653\n",
            "Model saved.\n",
            "Epoch [21/50] - Loss: 0.3615\n",
            "Model saved.\n",
            "Epoch [22/50] - Loss: 0.3578\n",
            "Model saved.\n",
            "Epoch [23/50] - Loss: 0.3544\n",
            "Model saved.\n",
            "Epoch [24/50] - Loss: 0.3511\n",
            "Model saved.\n",
            "Epoch [25/50] - Loss: 0.3480\n",
            "Model saved.\n",
            "Epoch [26/50] - Loss: 0.3451\n",
            "Model saved.\n",
            "Epoch [27/50] - Loss: 0.3422\n",
            "Model saved.\n",
            "Epoch [28/50] - Loss: 0.3395\n",
            "Model saved.\n",
            "Epoch [29/50] - Loss: 0.3369\n",
            "Model saved.\n",
            "Epoch [30/50] - Loss: 0.3343\n",
            "Model saved.\n",
            "Epoch [31/50] - Loss: 0.3319\n",
            "Model saved.\n",
            "Epoch [32/50] - Loss: 0.3296\n",
            "Model saved.\n",
            "Epoch [33/50] - Loss: 0.3273\n",
            "Model saved.\n",
            "Epoch [34/50] - Loss: 0.3252\n",
            "Model saved.\n",
            "Epoch [35/50] - Loss: 0.3231\n",
            "Model saved.\n",
            "Epoch [36/50] - Loss: 0.3210\n",
            "Model saved.\n",
            "Epoch [37/50] - Loss: 0.3190\n",
            "Model saved.\n",
            "Epoch [38/50] - Loss: 0.3171\n",
            "Model saved.\n",
            "Epoch [39/50] - Loss: 0.3153\n",
            "Model saved.\n",
            "Epoch [40/50] - Loss: 0.3134\n",
            "Model saved.\n",
            "Epoch [41/50] - Loss: 0.3116\n",
            "Model saved.\n",
            "Epoch [42/50] - Loss: 0.3099\n",
            "Model saved.\n",
            "Epoch [43/50] - Loss: 0.3082\n",
            "Model saved.\n",
            "Epoch [44/50] - Loss: 0.3065\n",
            "Model saved.\n",
            "Epoch [45/50] - Loss: 0.3049\n",
            "Model saved.\n",
            "Epoch [46/50] - Loss: 0.3033\n",
            "Model saved.\n",
            "Epoch [47/50] - Loss: 0.3018\n",
            "Model saved.\n",
            "Epoch [48/50] - Loss: 0.3002\n",
            "Model saved.\n",
            "Epoch [49/50] - Loss: 0.2986\n",
            "Model saved.\n",
            "Epoch [50/50] - Loss: 0.2971\n",
            "Model saved.\n",
            "Final model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Model Validation"
      ],
      "metadata": {
        "id": "R5PKl6u9xyAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_predictions(X_test, y_test, y_pred, task=\"binary\"):\n",
        "    df_test['true_label'] = y_test\n",
        "    df_test['predicted_label'] = y_pred\n",
        "\n",
        "    correct_preds = df_test[df_test['true_label'] == df_test['predicted_label']]\n",
        "    incorrect_preds = df_test[df_test['true_label'] != df_test['predicted_label']]\n",
        "\n",
        "    correct_examples = correct_preds.sample(n=min(3, len(correct_preds)), random_state=42)\n",
        "    incorrect_examples = incorrect_preds.sample(n=min(3, len(incorrect_preds)), random_state=42)\n",
        "\n",
        "    print(f\"Task: {task}\")\n",
        "    print(\"\\nCorrect Predictions:\")\n",
        "    print(correct_examples)\n",
        "\n",
        "    print(\"\\nIncorrect Predictions:\")\n",
        "    print(incorrect_examples)\n",
        "\n",
        "    return df_test"
      ],
      "metadata": {
        "id": "1g7Fgebmy2ee"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# running inference on test set\n",
        "y_pred_bin = predict(binary_mlp, X_test_bin, batch_size)\n",
        "y_pred_multi = predict(multi_mlp, X_test_multi, batch_size)\n",
        "\n",
        "\n",
        "# analyze binary predictions\n",
        "binary_results = analyze_predictions(X_test_bin, y_test_bin, y_pred_bin, task=\"binary\")\n",
        "\n",
        "# Analyze multi-class predictions\n",
        "multi_results = analyze_predictions(X_test_multi, y_test_multi, y_pred_multi, task=\"multiclass\")"
      ],
      "metadata": {
        "id": "WR7hTYDSyPB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Results"
      ],
      "metadata": {
        "id": "TeVC9VuU0fXD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "QVrpkQaKzxd_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import torch\n",
        "\n",
        "def evaluate(model, X_test, y_test, task=\"binary\", threshold=0.5):\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        # convert test features to PyTorch tensors\n",
        "        X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "        # get model outputs\n",
        "        outputs = model(X_test_t)\n",
        "\n",
        "        if task == \"binary\":\n",
        "            # for binary classification, apply threshold\n",
        "            preds = (outputs.squeeze().numpy() >= threshold).astype(int)\n",
        "        elif task == \"multiclass\":\n",
        "            # for multi-class classification, get the class with the highest score\n",
        "            preds = torch.argmax(outputs, dim=1).numpy()\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported task type: {task}. Use 'binary' or 'multiclass'.\")\n",
        "\n",
        "    # calculate accuracy and confusion matrix\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "\n",
        "    return accuracy, cm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion Matrix for binary classification:\n",
        "# [[TN, FP],\n",
        "# [FN, TP]]\n",
        "accuracy_bin, cm_bin = evaluate(binary_mlp, X_test_bin, y_test_bin, task=\"binary\")\n",
        "print(\"\\nBinary Test Accuracy:\", accuracy_bin)\n",
        "print(\"Binary Confusion Matrix:\")\n",
        "print(cm_bin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV7W0BW3snmg",
        "outputId": "83bc4311-e8dd-4450-e877-b121164e8e33"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Binary Test Accuracy: 0.9825\n",
            "Binary Confusion Matrix:\n",
            "[[983  17]\n",
            " [ 18 982]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multi-Class classification\n",
        "accuracy_multi, cm_multi = evaluate(multi_mlp, X_test_multi, y_test_multi, task=\"multiclass\")\n",
        "print(\"\\nMulti-Class Test Accuracy:\", accuracy_multi)\n",
        "print(\"Multi-Class Confusion Matrix:\")\n",
        "display(cm_multi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ai2-uI4vtQRc",
        "outputId": "f6140150-1174-44c1-fa54-3436976a87aa"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multi-Class Test Accuracy: 0.8578\n",
            "Multi-Class Confusion Matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[812,   2,  16,  41,   8,   5, 103,   0,  12,   1],\n",
              "       [  4, 963,   3,  21,   4,   0,   4,   0,   1,   0],\n",
              "       [ 17,   3, 749,  13, 125,   0,  89,   0,   4,   0],\n",
              "       [ 30,  14,   9, 871,  37,   1,  30,   0,   8,   0],\n",
              "       [  1,   1,  88,  42, 782,   0,  80,   0,   6,   0],\n",
              "       [  0,   3,   0,   0,   0, 945,   0,  26,   2,  24],\n",
              "       [149,   3,  89,  34,  84,   0, 625,   0,  16,   0],\n",
              "       [  0,   0,   0,   0,   0,  31,   0, 929,   1,  39],\n",
              "       [  7,   0,   7,   6,   4,   6,  15,   6, 949,   0],\n",
              "       [  1,   0,   0,   0,   0,   6,   0,  39,   1, 953]])"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ggZaP1pRjBnO"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}