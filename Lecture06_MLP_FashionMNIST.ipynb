{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac70d6ec-3389-43e6-bb93-78af240f8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Load and convert Fashion MNIST dataset to a DataFrame\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe74fb9-6c45-4390-aa03-a4e82f2bb697",
   "metadata": {},
   "source": [
    "### Pretend we are NOT doing this - imagine it being you donwloading data from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60335a3c-850c-4e7e-bca7-bb09d0784006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the Fashion MNIST dataset\n",
    "transform = transforms.ToTensor()  # Transform the data into tensors\n",
    "full_dataset = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c049b7-046a-46c1-af9a-f14eef3ba87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to a DataFrame\n",
    "# Each image is a 28x28 array, flatten it into a single row\n",
    "data_list = []\n",
    "for image, label in full_dataset:\n",
    "    flat_image = image.view(-1).numpy()  # Flatten the 28x28 image into a 1D array\n",
    "    data_list.append([*flat_image, label])\n",
    "\n",
    "# Create a DataFrame\n",
    "columns = [f\"pixel_{i}\" for i in range(28 * 28)] + [\"label\"]\n",
    "full_df = pd.DataFrame(data_list, columns=columns)\n",
    "\n",
    "# Split the DataFrame into train and test sets\n",
    "train_df, test_df = train_test_split(full_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the first few rows of each DataFrame\n",
    "print(\"Train DataFrame:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af516a95-6008-4f17-a255-73435ea77347",
   "metadata": {},
   "source": [
    "### Let's start here by examining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf2cf1-bc6a-46d6-a288-671e7b535b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(data_list, columns=columns)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61327d7e-6cd6-4f4e-b6a0-81d46910271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309bd9e-66ba-4429-9365-5ffa30d78716",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc22474-77b2-463e-a431-e0698f020315",
   "metadata": {},
   "source": [
    "## Helper to visualize a row of data - nice for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04db97-235a-49bb-b0c2-90b87fe298b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Function to display a greyscale image from a row\n",
    "def show_image_from_row(row, label):\n",
    "    # Reshape the row back to a 28x28 image\n",
    "    image = np.array(row).reshape(28, 28)\n",
    "    \n",
    "    # Plot the image\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Example: Display an image from the DataFrame\n",
    "example_row = train_df.iloc[0, :-1]  # First row (pixels only)\n",
    "example_label = train_df.iloc[0, -1]  # Corresponding label\n",
    "show_image_from_row(example_row, example_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f91906-d2e8-4c3c-8f6b-f9d26e8786b7",
   "metadata": {},
   "source": [
    "## Example Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc7cc7-b993-4577-8e90-46ac0404097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"\n",
    "        Initialize the dataset by passing a DataFrame.\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame with pixel data and labels.\n",
    "        \"\"\"\n",
    "        self.data = dataframe.iloc[:, :-1].values  # Features (all columns except the last)\n",
    "        self.labels = dataframe.iloc[:, -1].values  # Labels (last column)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve a single sample from the dataset.\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "        Returns:\n",
    "            (torch.Tensor, torch.Tensor): Tuple of features and label.\n",
    "        \"\"\"\n",
    "        # Convert the features and label to tensors\n",
    "        features = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return features, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d4ea93-1ac5-4072-a741-ed35f7344dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the DataFrame and create DataLoaders\n",
    "def create_train_test_dataloaders(dataframe, test_size=0.2, batch_size=64, shuffle=True):\n",
    "    \"\"\"\n",
    "    Split the DataFrame into train and test sets and create DataLoaders.\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame containing the data.\n",
    "        test_size (float): Proportion of the data to be used as test data.\n",
    "        batch_size (int): Number of samples per batch.\n",
    "        shuffle (bool): Whether to shuffle the data.\n",
    "    Returns:\n",
    "        tuple: (train_loader, test_loader)\n",
    "    \"\"\"\n",
    "    # Split the data into train and test sets\n",
    "    train_df, test_df = train_test_split(dataframe, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Create train and test datasets\n",
    "    train_dataset = CustomDataset(train_df)\n",
    "    test_dataset = CustomDataset(test_df)\n",
    "    \n",
    "    # Create DataLoaders for train and test sets\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4ddcf-2c38-4aef-8c48-e371c48c666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## command + /\n",
    "\n",
    "# # Example usage: Creating train and test DataLoaders\n",
    "# train_loader, test_loader = create_train_test_dataloaders(train_df, test_size=0.2, batch_size=32)\n",
    "\n",
    "# # Example: Check the first batch from the train DataLoader\n",
    "# for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "#     print(f\"Train Batch {batch_idx + 1}\")\n",
    "#     print(\"Features shape:\", features.shape)\n",
    "#     print(\"Labels shape:\", labels.shape)\n",
    "#     break  # Display only the first batch\n",
    "\n",
    "# # Example: Check the first batch from the test DataLoader\n",
    "# for batch_idx, (features, labels) in enumerate(test_loader):\n",
    "#     print(f\"Test Batch {batch_idx + 1}\")\n",
    "#     print(\"Features shape:\", features.shape)\n",
    "#     print(\"Labels shape:\", labels.shape)\n",
    "#     break  # Display only the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6666c-094c-46f6-94e3-202970a58c6c",
   "metadata": {},
   "source": [
    "## Manually Build dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3919e8ab-f84f-4f2b-90f0-5f148fdd7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Create a DataLoader\n",
    "\n",
    "\n",
    "# Convert the DataFrame back to PyTorch tensors\n",
    "X_train = torch.tensor(train_df.iloc[:, :-1].values, dtype=torch.float32)  # All pixels\n",
    "y_train = torch.tensor(train_df[\"label\"].values, dtype=torch.long)  # Labels\n",
    "# Convert the DataFrame back to PyTorch tensors\n",
    "X_test = torch.tensor(test_df.iloc[:, :-1].values, dtype=torch.float32)  # All pixels\n",
    "y_test = torch.tensor(test_df[\"label\"].values, dtype=torch.long)  # Labels\n",
    "\n",
    "# Create a TensorDataset\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Create a DataLoader for batching and shuffling\n",
    "batch_size = 64  # Number of samples per batch\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Example: Check the first batch\n",
    "for batch in train_loader:\n",
    "    images, labels = batch\n",
    "    print(f\"Batch size: {images.shape}, Labels: {labels.shape}\")\n",
    "    break\n",
    "# Example: Check the first batch\n",
    "for batch in test_loader:\n",
    "    images, labels = batch\n",
    "    print(f\"Batch size: {images.shape}, Labels: {labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ed4f6-35b7-46f4-b2b0-910b04caaaf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977c7cbc-e0f7-42eb-895a-e5ae019453a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed96bbf-bdec-4491-b486-1567c3743339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define the neural network\n",
    "\n",
    "# Define a feedforward network for classification\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # First fully connected layer\n",
    "        self.relu = nn.ReLU()  # ReLU activation\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  # Output layer for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)  # First layer\n",
    "        x = self.relu(x)  # Activation\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_size = 28 * 28  # 784 input features (flattened image)\n",
    "hidden_size = 128  # Number of neurons in the hidden layer\n",
    "num_classes = 10  # 10 classes for Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4bb09e-03e2-4005-be42-c5e2d81c97f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b48df-879a-4318-b7ab-4772d77a47fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c6c8b-58c8-45bd-8d61-cde8ccf9fa0a",
   "metadata": {},
   "source": [
    "### for later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832696a-d277-4eac-9397-67deeb7e8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = (\n",
    "#     \"cuda\"\n",
    "#     if torch.cuda.is_available()\n",
    "#     else \"mps\"\n",
    "#     if torch.backends.mps.is_available()\n",
    "#     else \"cpu\"\n",
    "# )\n",
    "# model.to(\"cpu\")\n",
    "# print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34623666-a418-4165-99db-f899cb05ad8d",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4d01e-598e-48af-a60d-fd467cacfe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23975eea-fb46-4886-bd99-40a1d87806b1",
   "metadata": {},
   "source": [
    "## Saving and loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476dab9-c164-4b55-af0a-0c1781d4468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model after training\n",
    "torch.save(model.state_dict(), \"fashion_mnist_model.pth\")\n",
    "print(\"Model saved as 'fashion_mnist_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c6f1ff-1597-4c6d-aa9b-ae2f591f7dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model for inference\n",
    "model = SimpleNN(input_size, hidden_size, num_classes)  # Reinitialize the model structure\n",
    "model.load_state_dict(torch.load(\"fashion_mnist_model.pth\"))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "print(\"Model loaded and ready for inference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560b056-d02f-4806-83d7-c1758ec17cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b93f4aa-dd26-40a1-b787-bde14fdeae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Inference loop\n",
    "# Running inference\n",
    "model.eval()  # Set the model to evaluation mode (disables dropout, etc.)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62328d-402a-4070-9291-755c2a73909b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e6d898-a518-4a8c-aec7-ba27404a59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate predictions for the entire dataset\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_predictions.extend(predicted.numpy())\n",
    "\n",
    "# Compute and plot the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(10)))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79eadfc-1464-4321-9daa-a3203e84e0dc",
   "metadata": {},
   "source": [
    "### Inspect a row of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef629ac2-a678-424f-9433-b93215267a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run inference on a single row of data\n",
    "def run_inference_on_row(row, label, model):\n",
    "    # Convert the row into a tensor\n",
    "    row_tensor = torch.tensor(row.values, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(row_tensor)  # Raw logits\n",
    "        probabilities = torch.softmax(logits, dim=1)  # Apply softmax to convert logits to probabilities\n",
    "\n",
    "    # Get predicted label\n",
    "    predicted_label = torch.argmax(probabilities).item()\n",
    "\n",
    "    # Print details\n",
    "    print(\"Logits:\", logits.numpy())\n",
    "    print(\"Softmax Probabilities:\", probabilities.numpy())\n",
    "    print(\"Correct Label:\", label)\n",
    "    print(\"Predicted Label:\", predicted_label)\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "# Example: Run inference on a single row\n",
    "example_row = test_df.iloc[10, :-1]  # 10th row (pixels only)\n",
    "example_label = test_df.iloc[10, -1]  # Corresponding label\n",
    "run_inference_on_row(example_row, example_label, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a60cd76-3af6-4882-b79e-0d6a194ef570",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Display examples of correct and incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187fcc0c-4760-4832-8ee9-ee1c4b0c6bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_examples(data_df, model, correct=True, num_examples=3):\n",
    "    count = 0\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    for idx, row in data_df.iterrows():\n",
    "        if count >= num_examples:\n",
    "            break\n",
    "\n",
    "        # Extract image and label\n",
    "        image_row = row[:-1]\n",
    "        true_label = row[-1]\n",
    "\n",
    "        # Run inference\n",
    "        predicted_label = run_inference_on_row(image_row, true_label, model)\n",
    "\n",
    "        # Check if prediction is correct\n",
    "        if (predicted_label == true_label and correct) or (predicted_label != true_label and not correct):\n",
    "            # Plot the image\n",
    "            plt.subplot(1, num_examples, count + 1)\n",
    "            image = image_row.values.reshape(28, 28)  # Reshape to 28x28\n",
    "            plt.imshow(image, cmap=\"gray\")\n",
    "            plt.title(f\"True: {true_label}, Pred: {predicted_label}\")\n",
    "            plt.axis(\"off\")\n",
    "            count += 1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a882db3-f783-431d-b340-405764002091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Show 3 correct predictions\n",
    "print(\"Examples of Correct Predictions:\")\n",
    "display_examples(train_df, model, correct=True, num_examples=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4bfd43-bb28-49a7-a7bc-1d4e9a8c65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Show 3 incorrect predictions\n",
    "print(\"Examples of Incorrect Predictions:\")\n",
    "display_examples(train_df, model, correct=False, num_examples=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d5a1dd-084d-4245-84ed-a32898f82d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
