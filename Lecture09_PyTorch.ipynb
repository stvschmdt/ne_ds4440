{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to PyTorch ðŸ”¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Before starting this tutorial, make sure you have PyTorch installed. You can install it using:\n",
    "```bash\n",
    "pip install torch torchvision\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is one of the leading deep learning frameworks, particularly popular in research and academia. It offers:\n",
    "- Dynamic computational graphs (unlike static graphs in early TensorFlow)\n",
    "- Python-first approach with familiar syntax\n",
    "- Rich ecosystem of tools and libraries\n",
    "- Strong GPU acceleration support\n",
    "- Active community and extensive documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About This Tutorial\n",
    "This tutorial assumes you have basic Python knowledge and understanding of fundamental machine learning concepts. We'll cover:\n",
    "1. Tensors - The fundamental PyTorch data structure\n",
    "2. Autograd - Automatic differentiation system\n",
    "3. Neural Network Modules\n",
    "4. Training a Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PyTorch Tensors\n",
    "Tensors are similar to arrays but with additional features like GPU support and automatic differentiation tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([1, 2, 3, 4, 5])\n",
      "Type: torch.int64\n",
      "Shape: torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Create a tensor\n",
    "x = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(f\"Tensor: {x}\")\n",
    "print(f\"Type: {x.dtype}\")\n",
    "print(f\"Shape: {x.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tensors\n",
    "PyTorch provides multiple ways to create tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From array: tensor([1, 2, 3])\n",
      "\n",
      "Zeros:\n",
      " tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "\n",
      "Ones:\n",
      " tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "\n",
      "Random:\n",
      " tensor([[0.1351, 0.2982, 0.9185],\n",
      "        [0.7382, 0.9896, 0.3468]])\n"
     ]
    }
   ],
   "source": [
    "# From Python list/NumPy array\n",
    "\n",
    "array = np.array([1, 2, 3])\n",
    "tensor_from_array = torch.from_numpy(array)\n",
    "\n",
    "# Zero tensor\n",
    "zeros = torch.zeros(3, 2)\n",
    "\n",
    "# One tensor\n",
    "ones = torch.ones(2, 2)\n",
    "\n",
    "# Random tensor\n",
    "random = torch.rand(2, 3)\n",
    "\n",
    "print(\"From array:\", tensor_from_array)\n",
    "print(\"\\nZeros:\\n\", zeros)\n",
    "print(\"\\nOnes:\\n\", ones)\n",
    "print(\"\\nRandom:\\n\", random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operations\n",
    "PyTorch supports various operations similar to NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: tensor([5, 7, 9])\n",
      "Multiplication: tensor([ 4, 10, 18])\n",
      "Matrix Multiplication: tensor(32)\n",
      "\n",
      "Original:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Reshaped: tensor([[1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Basic arithmetic\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "print(\"Addition:\", a + b)\n",
    "print(\"Multiplication:\", a * b)\n",
    "print(\"Matrix Multiplication:\", torch.matmul(a, b))\n",
    "\n",
    "# Reshaping\n",
    "c = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"\\nOriginal:\\n\", c)\n",
    "print(\"Reshaped:\", c.reshape(1, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Support\n",
    "One of PyTorch's key features is seamless GPU support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal Performance Shaders on Apple Silicon\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA for NVIDIA GPUs\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fallback to CPU\n",
    "    \n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move tensor to GPU if available\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x = x.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Autograd: Automatic Differentiation\n",
    "PyTorch's autograd system enables automatic computation of gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz/dx: 4.0\n",
      "dz/dy: 27.0\n"
     ]
    }
   ],
   "source": [
    "# Create tensors with gradient tracking\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# Perform operations\n",
    "z = x**2 + y**3\n",
    "\n",
    "# Compute gradients\n",
    "z.backward()\n",
    "\n",
    "print(f\"dz/dx: {x.grad}\")  # Should be 4.0 (derivative of x^2 is 2x)\n",
    "print(f\"dz/dy: {y.grad}\")  # Should be 27.0 (derivative of y^3 is 3y^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Network Modules\n",
    "PyTorch provides a high-level API for building neural networks through `torch.nn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (layer1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (layer2): Linear(in_features=5, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(10, 5)\n",
    "        self.layer2 = nn.Linear(5, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "# Create model instance\n",
    "model = SimpleNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training a Simple Neural Network\n",
    "Let's put everything together to train a simple neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Loss: 0.1257\n",
      "Epoch [40/100], Loss: 0.0927\n",
      "Epoch [60/100], Loss: 0.0800\n",
      "Epoch [80/100], Loss: 0.0738\n",
      "Epoch [100/100], Loss: 0.0696\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Generate synthetic data\n",
    "X = torch.randn(100, 10)  # 100 samples, 10 features\n",
    "y = torch.sum(X, dim=1, keepdim=True) * 0.1  # Simple target function\n",
    "\n",
    "# Model, loss function, and optimizer\n",
    "model = SimpleNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    # Forward pass\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common PyTorch Patterns and Best Practices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading\n",
    "PyTorch provides efficient data loading utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create data loader\n",
    "dataset = CustomDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/vhwm53rj4tnfvv9lgq9m3x5w0000gn/T/ipykernel_77994/4089310465.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load('model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Load model\n",
    "loaded_model = SimpleNN()\n",
    "loaded_model.load_state_dict(torch.load('model.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training and Evaluation Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training mode\n",
    "model.train()\n",
    "# ... training code ...\n",
    "\n",
    "# Evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    test_output = model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Layers and Activation Functions\n",
    "PyTorch provides many built-in layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common layers\n",
    "conv = nn.Conv2d(3, 64, kernel_size=3)  # Convolutional layer\n",
    "pool = nn.MaxPool2d(2)  # Max pooling\n",
    "dropout = nn.Dropout(0.5)  # Dropout\n",
    "batch_norm = nn.BatchNorm2d(64)  # Batch normalization\n",
    "\n",
    "# Activation functions\n",
    "relu = nn.ReLU()\n",
    "sigmoid = nn.Sigmoid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "To continue learning PyTorch:\n",
    "1. Explore the [PyTorch documentation](https://pytorch.org/docs/stable/index.html)\n",
    "2. Try implementing different neural network architectures\n",
    "3. Practice with real-world datasets\n",
    "4. Experiment with more advanced features like custom loss functions and optimizers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
